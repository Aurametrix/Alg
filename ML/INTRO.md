### Deep Learning
+ [Theories of deep learning](https://stats385.github.io/), [GH](https://github.com/stats385/stats385.github.io)
+ [Andre Ng's online course](https://www.coursera.org/specializations/deep-learning)
+ [Brief History](http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/)


+ [YouTube Introduction to Deep Learning](https://www.youtube.com/watch?v=S75EdAcXHKk)


### DIGITS

+ [Nvidia Developer](https://developer.nvidia.com/digits)
+ [Github](https://github.com/NVIDIA/DIGITS)


+ [Kaggle Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)


### ML

+ [YouTube Machine Learning](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)
+ [CS231n Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/)
+ [TensorFlow and deep learning](https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd)


+ [Semantic segmentation](https://github.com/mrgloom/awesome-semantic-segmentation)

### ML Models implemented in Tensor Flow

- [https://github.com/stanfordmlgroup/tf-models/tree/master/autoencoder](autoencoder) -- various autoencoders
- [https://github.com/stanfordmlgroup/tf-models/tree/master/inception](inception) -- deep convolutional networks for computer vision
- [https://github.com/stanfordmlgroup/tf-models/tree/master/namignizer](namignizer) -- recognize and generate names
- [https://github.com/stanfordmlgroup/tf-models/tree/master/neural_gpu](neural_gpu) -- highly parallel neural computer
- [https://github.com/stanfordmlgroup/tf-models/tree/master/privacy](privacy) -- privacy-preserving student models from multiple teachers
- [https://github.com/stanfordmlgroup/tf-models/tree/master/resnet](resnet) -- deep and wide residual networks
- [https://github.com/stanfordmlgroup/tf-models/tree/master/slim](slim) -- image classification models in TF-Slim
- [https://github.com/stanfordmlgroup/tf-models/tree/master/swivel](swivel) -- the Swivel algorithm for generating word embeddings
- [https://github.com/stanfordmlgroup/tf-models/tree/master/syntaxnet](syntaxnet) -- neural models of natural language syntax
- [https://github.com/stanfordmlgroup/tf-models/tree/master/textsum](textsum) -- sequence-to-sequence with attention model for text summarization.
- [https://github.com/stanfordmlgroup/tf-models/tree/master/transformer](transformer) -- spatial transformer network, which allows the spatial manipulation of data within the network
- [https://github.com/stanfordmlgroup/tf-models/tree/master/im2txt](im2txt) -- image-to-text neural network for image captioning.


### Tensors and Dynamic neural networks

* [Pytorch](http://pytorch.org/) - a deep learning framework that puts Python first

* [DyNet â€“ Dynamic neural network library](https://github.com/clab/dynet)

TensorFlow is "Define-and-Run". Chainer, PyTorch, and DyNet are "Define-by-Run", as the graph structure is defined on-the-fly via the actual forward computation.


### Interesting papers

[Learning on just one image](https://dmitryulyanov.github.io/deep_image_prior) - [code](https://github.com/DmitryUlyanov/deep-image-prior)
