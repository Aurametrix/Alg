###
* [BioGPT](https://github.com/microsoft/BioGPT) - the implementation of [2022 article](https://academic.oup.com/bib/article/23/6/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9&login=false)
* [BlenderGPT](https://github.com/gd3kr/BlenderGPT) - Generate Blender Python code from natural language commands
* [ViperGPT](https://viper.cs.columbia.edu/) - Visual Inference via Python Execution for Reasoning
* [PrivateGPT](https://github.com/imartinez/privateGPT) - Ask questions to your documents without an internet connection, using the power of LLMs
* [DocGPT](https://github.com/FeatureBaseDB/DocGPT/tree/main) - document organization
* [GeneGPT](https://github.com/ncbi/GeneGPT) - tool-augmented LLM for improved access to biomedical information
* [SpeechGPT](https://github.com/0nutation/SpeechGPT/tree/main/speechgpt-gen) - Scaling Chain-of-Information Speech Generation - [paper](https://0nutation.github.io/SpeechGPT.github.io/)
* [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/)
* [ChatGPT talks to your AWS infrastructure footprint](https://www.akitasoftware.com/blog-posts/we-built-an-exceedingly-polite-ai-dog-that-answers-questions-about-your-apis)
* [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g) - by Andrej Karpathy
* [ChatGPR & Whisper APIs](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)
* [OpenAI Python Library](https://github.com/openai/openai-python)
* [Streaming in the Assistant's API](https://platform.openai.com/docs/assistants/overview?context=with-streaming)
* [List of alternatives to ChatGPT](https://github.com/nichtdax/awesome-totally-open-chatgpt)
* [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)
* [ChatGPT for your data](https://github.com/raghavan/PdfGptIndexer)
* [Chat with your data using LangChain, Pinecone, and Airbyte](https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain); [github](https://github.com/airbytehq/tutorial-connector-dev-bot)
* [Custom versions of ChatGPT](https://openai.com/blog/introducing-gpts)
* [Danswer](https://github.com/danswer-ai/danswer) - ask your docs
* [QuiLLMan](https://github.com/modal-labs/quillman) - Voice Chat with LLMs
* [VOcode](https://github.com/vocodedev/vocode-python) - build voice-based LLM apps in minutes
* [ReTellAI](https://news.ycombinator.com/item?id=39453402) - conversational speech API for your LLM
* [WEB LLM](https://github.com/mlc-ai/web-llm) - [bringing chatbots to web browsers](https://mlc.ai/web-llm/)
* [IPython-GPT](https://github.com/santiagobasulto/ipython-gpt) - IPython ChatGPT extension
* [chat-gpt-jupyter-extension](https://github.com/jflam/chat-gpt-jupyter-extension) 
* [jupytee](https://github.com/fperez/jupytee) 
* [jupyter-voicepilot](https://github.com/JovanVeljanoski/jupyter-voicepilot)
* [Jupyter AI](https://jupyter-ai.readthedocs.io/en/latest/)
* [Tensorli](https://github.com/joennlae/tensorli) - Minimalistic implementation of a GPT-like transformer using only numpy (<650 lines).
* [CROSS-AXIS TRANSFORMER WITH 2D ROTARY EMBEDDINGS](https://github.com/ElleLeonne/Cross-Axis-Transformer) - [CAT arxiv paper](https://arxiv.org/pdf/2311.07184v1.pdf)
* [Prompt Engineering](https://gist.github.com/Hellisotherpeople/45c619ee22aac6865ca4bb328eb58faf)
* [ChatGPT System Prompts](https://github.com/spdustin/ChatGPT-AutoExpert/blob/main/System%20Prompts.md)
* [Open AI Moonwalk proposal](https://github.com/OAI/moonwalk)
* [Open AI transformer-debugger](https://github.com/openai/transformer-debugger)
* [VIT](https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py) - Vision Transformers; [Visual Guide](https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html)
* [ChatHUB](https://github.com/chathub-dev/chathub/blob/main/README.md) - Use ChatGPT, Bing, Bard and Claude in One App
* [GPT engineer](https://github.com/AntonOsika/gpt-engineer) -  generates an entire codebase based on a prompt
* [ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin)
* [Wanderlust](https://github.com/widgetti/wanderlust) - Wanderlust app  rebuilt in Python using Solara
* [Typer assistant](https://github.com/eblume/TyperAssistant) - turn any Typer add into a function-calling assistant
* [GPT script to check Wikipedia](https://gwern.net/tla) - [python](https://gwern.net/static/build/latex2unicode.py)
* [Daily DALL-E](https://github.com/DerekCuevas/daily-dall-e) - Once a day (via a GitHub Action running in the repo), this project queries Google Trends and then uses OpenAI's ChatGPT and Dall-E to produce unique artwork relevant to today.
* [Automating the creation of foundation models](https://github.com/SakanaAI/evolutionary-model-merge); [arxiv paper](https://arxiv.org/abs/2403.13187)
* [NeumAI](https://github.com/NeumTry/NeumAI) -  framework focuses on RAG data pipelines
* [KG-RAG](https://github.com/BaranziniLab/KG_RAG) -  Knowledge Graph-based Retrieval Augmented Generation
* [RAGflow](https://github.com/infiniflow/ragflow) - open-source RAG engine based on OCR and document parsing 
* [BARD Extensions](https://bard.google.com/extensions?hl=en)
* [GPT fast](https://github.com/pytorch-labs/gpt-fast) - pytorch-native transformer text generation
* [MAMBA Chat](https://github.com/havenhq/mamba-chat) - language model based on a state-space model architecture, not a transformer
        - [MAMBA by anakin.ai](https://anakin.ai/blog/mamba/)
        - [Can we Reach AGI with just LLMS](https://www.youtube.com/watch?v=jq0QeWIgvfw)  - Dr.Waku's Youtube
        - [MAMBA explained](https://thegradient.pub/mamba-explained/)

### Lists of GPTs

+ [Awesome GPTs](https://github.com/friuns2/Awesome-GPTs-Big-List/)
+ [GPTs for me](https://gptsfor.me/)
+ [Top GPTs](https://www.topgpts.ai/)
+ [Awesome GPTs](https://awesomegpts.pro/)
+ [GPTs list](https://gpts-list.com/)


### LLAMA
+ [FB LLAMA](https://github.com/facebookresearch/llama)
+ [Finetune LLaMA-7B on commodity GPUs using your own text](https://github.com/lxe/simple-llama-finetuner)
+ [Guide to fine-tuning LLAMA](https://ragntune.com/blog/guide-fine-tuning-code-llama)
+ [Minimal LLAMA](https://github.com/zphang/minimal-llama/)) - code for running and fine-tuning LLaMA.
+ [Low-Rank LLaMA Instruct-Tuning](https://github.com/lxe/simple-llama-finetuner ); [py](https://github.com/tloen/alpaca-lora/blob/main/finetune.py)
+ [Run LLAMA and ALPACA on your computer](https://github.com/cocktailpeanut/dalai)
+ [Nougat](https://github.com/facebookresearch/nougat) - Neural Optical Understanding for Academic Documents
+ [get LLAMA running locally](https://github.com/ggerganov/llama.cpp )
+ [TinyLlama](https://github.com/jzhang38/TinyLlama) -  1.1B Llama model on 3 trillion tokens -[arXiv paper](https://arxiv.org/abs/2401.02385)
+ 

###
+ [GROK](https://github.com/xai-org/grok-1)

### Programmable ChatGPT
+ [ChatGPT wrapper](https://github.com/mmabrouk/chatgpt-wrapper)
+ [Prompt injection on Bing Chat](https://greshake.github.io/)
+ [Jailbreak Chat](https://www.jailbreakchat.com/)
+ [WordGPT](https://github.com/filippofinke/WordGPT)
+ [REddit Profile Analyzer](https://github.com/grays42/reddit-profile-analyzer) - with an API key for ChatGPT.

+ [Visual ChatGPT](https://github.com/microsoft/visual-chatgpt) - connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting
      + [AI tokenizer](https://platform.openai.com/tokenizer)
      + [Tiktoken](https://github.com/openai/tiktoken)
      + [Tiktokenizer](https://tiktokenizer.vercel.app/)

+ [Plugins](https://openai.com/blog/chatgpt-plugins)
    + [wolfram](https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/)
 

[Coscientist](https://github.com/gomesgroup/coscientist) - 
[Autonomous chemical research with large language models](https://www.nature.com/articles/s41586-023-06792-0)


###

[Mass Editing Memory in a Transformer](https://memit.baulab.info/) - [code](https://github.com/kmeng01/memit) - [arXiv paper](https://arxiv.org/abs/2210.07229)

###
[Chatbot kit](https://chatbotkit.com/)


The following models are considered GPT 3.5:

- code-davinci-002

- text-davinci-002

- text-davinci-003
- 
[prompttools](https://github.com/hegelai/prompttools) - fir evaluations LLMs and vector dbs

[Magentic](https://github.com/jackmpcollins/magentic) - to integrate Large Language Models into code (as Python functions)

###
[jupyter-extension](https://github.com/TiesdeKok/chat-gpt-jupyter-extension) - A browser extension to provide various helper functions in Jupyter Notebooks and Jupyter Lab, powered by ChatGPT.
[social](https://github.com/riverscuomo/social) - A python package that uses OpenAI to generate a response to a social media mention

[Freely Available GPT models](https://huggingface.co/EleutherAI/gpt-neo-2.7B)

[Nendo colab](https://colab.research.google.com/drive/1uGQIejuCKKEQrFBgzaHtdCYHEIFbJD6l) - 

• Model 1 generates finest vintage Dub music [musicgen-stereo-dub](https://huggingface.co/pharoAIsanders420/musicgen-stereo-dub)
• Model 2 generates Boom Bap Hip Hop tunes [Hiphop](https://huggingface.co/pharoAIsanders420/musicgen-medium-hiphop )
• Model 3 generates rolling Drum'n'Bass bangers [DNB](https://huggingface.co/pharoAIsanders420/musicgen-small-dnb)




###

[reverse engineered chatGPT API](https://github.com/acheong08/ChatGPT)

[built with GPT](https://github.com/elyase/awesome-gpt3)

[Basic Search for a Website](https://platform.openai.com/docs/tutorials/web-qa-embeddings/how-to-build-an-ai-that-can-answer-questions-about-your-website): 
[full code](https://github.com/openai/openai-cookbook/tree/main/solutions/web_crawl_Q%26A)

[Open Assistant](https://github.com/LAION-AI/Open-Assistant) - with LAION AI - [main page](https://open-assistant.io/)

[GPTalk 0.0.4.4](https://github.com/0ut0flin3/GPTalk)

[github support bot with GPT3](https://dagster.io/blog/chatgpt-langchain)

###
https://github.com/mmabrouk/chatgpt-wrapper
pip install git+https://github.com/mmabrouk/chatgpt-wrapper
(uses playwright: https://playwright.dev/)
pip freeze | grep playwright 
playwright==1.28.0
chatgpt install
The SDK provides a command-line interface

### The second open-source SDK is chatgpt-python
https://github.com/labteral/chatgpt-python


### Official instructions

Python Flask
git clone https://github.com/openai/openai-quickstart-python.git
If you prefer not to use git, you can alternatively download the code using this zip file.

Add your API key
Navigate into the project directory and make a copy of the example environment variables file.

cd openai-quickstart-python
cp .env.example .env
Copy your secret API key and set it as the OPENAI_API_KEY in your newly created .env file. If you haven't created a secret key yet, you can do so below.

SECRET KEY	CREATED	LAST USED	
sk-...S3Tk
Dec 5, 2022	Never	

Run the app
Run the following commands in the project directory to install the dependencies and run the app. When running the commands, you may need to type python3/pip3 instead of python/pip depending on your setup.

python -m venv venv
. venv/bin/activate
pip install -r requirements.txt
flask run
Open http://localhost:5000 in your browser and you should see the pet name generator!

Understand the code
Open up app.py in the openai-quickstart-python folder. At the bottom, you’ll see the function that generates the prompt that we were using above. Since users will be entering the type of animal their pet is, it dynamically swaps out the part of the prompt that specifies the animal.

def generate_prompt(animal):
    return """Suggest three names for an animal that is a superhero.

Animal: Cat
Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
Animal: Dog
Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
Animal: {}
Names:""".format(animal.capitalize())
On line 14 in app.py, you’ll see the code that sends the actual API request. As mentioned above, it uses the completions endpoint with a temperature of 0.6.


response = openai.Completion.create(
  model="text-davinci-003",
  prompt=generate_prompt(animal),
  temperature=0.6
)

### Projects

[Autolabel](https://github.com/refuel-ai/autolabel) - library to label, clean and enrich text datasets with any Large Language Models (LLM)

[Neuroengine](https://www.neuroengine.ai/) - Share your AI models with the world

[PlotAI](https://github.com/mljar/plotai) - plot with LLMs

[extracting meta-learned reinforcement learning algorithms from a large language model](https://github.com/keskival/king-algorithm-manifesto)

[Browser Automation with LLMs and Computer Vision](https://github.com/Skyvern-AI/skyvern)

[Graph of Thought paper](https://arxiv.org/abs/2308.09687), natural extension of CoT  [LLMtaskgraph](https://github.com/knexer/llmtaskgraph)
beyond paradigms such as Chain-of-Thought or Tree of Thoughts (ToT)


[LLMs with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)

[DIFY](https://github.com/langgenius/dify) - a visual workflow to build/test LLM applications 

[Magick](https://github.com/Oneirocom/Magick) - visual AIDE (Artificial Intelligence Development Environment) for no-code data pipelines and multimodal agents. 

[RLHF](https://datadreamer.dev/docs/latest/pages/get_started/quick_tour/aligning.html) -  a LLM in <50 lines of Python


[Why are most LLM libraries dead projects now?](https://news.ycombinator.com/item?id=37404949)


### Commercial Platforms to build ChatGPT Apps

https://www.quickchat.ai
https://www.chatbase.co
https://myaskai.com
https://libraria.dev/

https://slite.com/ask
https://builtbyjesse.com
https://meetcody.ai
https://invictai.io/
https://gpt-trainer.com

https://www.chatnode.ai
https://retune.so/ 

https://www.eesel.app/slack - 
[JiggyBase](https://jiggy.ai/#!) - now available in ChatGPT Plugin Store
https://www.askcorpora.com/ 
https://www.synna.ai/ 
https://punya.ai/ 
https://whismer.com 
https://flower.dev/ 
https://www.chatdox.com/
https://retool.com/products/ai

### working with LLMs

- [vllm](https://github.com/vllm-project/vllm) - Inference and serving engine for LLMs
- [ollama](https://github.com/jmorganca/ollama) - Go project to run, create and share LLMs
- [The initial versions of the Ollama Python and JavaScript libraries are now available](https://ollama.ai/blog/python-javascript-libraries)
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- [LLM engine](https://github.com/scaleapi/llm-engine)
- [LAMINI](https://www.lamini.ai/) - LLM platform
- [GPT4all](https://github.com/nomic-ai/gpt4all)
- [skypilot](https://github.com/skypilot-org/skypilot)
- [HuggingFace Transformers](https://github.com/huggingface/transformers/releases)
- [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ)
- [OnPrem.LLM](https://github.com/amaiya/onprem) - Run ChatGPT-like LLMs on your laptop in 3 lines of code
- [BoCoEL](https://github.com/rentruewang/bocoel) - Bayesian Optimization as a Coverage Tool for Evaluating Large Language Models
- [TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM/) - optimises inference time for LLMs on Nvidia cards.
- [thin wrapper around TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.

### Animated AI

+ [AnimatedAI](https://animatedai.github.io/)
+ [CNN Explainer](https://poloclub.github.io/cnn-explainer/)
+ [Tools to Visualkize Architecture of NN](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)
+ [Tenzorflow playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.14660&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)
+ [Convolutions](https://github.com/3b1b/videos/tree/master/_2023/convolutions2)

### MISC

+ [GPU calc](https://rahulschand.github.io/gpu_poor/) - calculate GPU memory requirement and token/s for any LLM
+ [Gen AI for beginners](https://microsoft.github.io/generative-ai-for-beginners/#/)
+ [Kagi's VectorDB](https://vectordb.com/)

### Autogen - a framework for the development of LLM applications using multiple agents that can converse with each other to solve tasks.
+ [Notebook](https://github.com/microsoft/autogen/tree/main/notebook)
+ [Group Chat](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb)
+ [Matthew Berman's video](https://www.youtube.com/watch?v=10FCv-gCKug) - using any open-source model with AutoGen using LMStudio
+ [LM Stuio](https://news.ycombinator.com/item?id=38377072)
+ [Communicative Agents for Software Development]([Communicative Agents for Software Development](https://github.com/OpenBMB/ChatDev))


### ACTIONS

+ [Repo for custom actions](https://github.com/bapo2/gpt-actions)
+ [GPT billing](https://github.com/Engine-Labs/gpt-billing-template)

  ###
 + [The lifecycle of a code AI completion](https://sourcegraph.com/blog/the-lifecycle-of-a-code-ai-completion)
 + [Micrograd CUDA](https://github.com/mlecauchois/micrograd-cuda)
